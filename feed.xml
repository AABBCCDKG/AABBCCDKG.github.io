<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://aabbccdkg.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://aabbccdkg.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-04T22:25:40+00:00</updated><id>https://aabbccdkg.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">åšå£«ç”³è¯·è®°å½•(2)</title><link href="https://aabbccdkg.github.io/blog/2024/phd-application(2)/" rel="alternate" type="text/html" title="åšå£«ç”³è¯·è®°å½•(2)"/><published>2024-09-04T00:32:13+00:00</published><updated>2024-09-04T00:32:13+00:00</updated><id>https://aabbccdkg.github.io/blog/2024/phd-application(2)</id><content type="html" xml:base="https://aabbccdkg.github.io/blog/2024/phd-application(2)/"><![CDATA[<p>è¾¾åˆ°ç›®æ ‡çš„è·¯å¾„æœ‰å¾ˆå¤šï¼Œä½†ç›´çº¿æœ€çŸ­ã€‚åœ¨è¿™æ¡ç›´çº¿ä¸Šåˆ†å¸ƒç€éœ€è¦è§£å†³çš„é—®é¢˜ - ç¬¦åˆäºŒå…«å®šå¾‹ã€‚æ¯æ¬¡å‘ç»éªŒä¸°å¯Œçš„äººè¯·æ•™ï¼Œéƒ½æ˜¯åœ¨ç›´çº¿ä¸Šè§£å†³ä¸€ä¸ªå°æ ¸å¿ƒé—®é¢˜ã€‚å› æ­¤ï¼ŒOffice Hourå’Œå‘å‰è¾ˆè¯·æ•™çš„æ—¶é—´å æ¯”è¶Šå¤§ï¼Œæˆæ•ˆè¶Šæ˜¾è‘—ã€‚åœ¨åšå£«é˜¶æ®µï¼Œå¯¼å¸ˆä¸å­¦ç”Ÿçš„å…³ç³»ä¸å†æ˜¯ä¼ ç»Ÿæ„ä¹‰ä¸Šâ€œä¼ é“æˆä¸šè§£æƒ‘â€çš„å¸ˆç”Ÿå…³ç³»ï¼Œè€Œæ›´åƒæ˜¯åå‹¤ä¿éšœå’Œå‰çº¿éƒ¨é˜Ÿã€‚å­¦ç”Ÿå¤„åœ¨ç§‘ç ”å·¥ä½œçš„æœ€å‰çº¿ï¼Œè´Ÿè´£å®é™…çš„ç ”ç©¶å’Œæ¢ç´¢ï¼Œè€Œå¯¼å¸ˆçš„è§’è‰²æ›´å€¾å‘äºä¸ºå­¦ç”Ÿæä¾›èµ„æºã€æŒ‡å¯¼æ–¹å‘å’Œä»¥åŠä¸ºå­¦ç”Ÿé—¯çš„ç¥¸å…œåº•ã€‚è¿™æ„å‘³ä¼˜ç§€çš„åšå£«å€™é€‰äººå¸¸å¸¸æ˜¯å…ˆæœ‰äº†å¼ºçƒˆçš„ç§‘ç ”æ„¿æœ›ï¼Œå¹¶ä¸”éœ€è¦èµ„æºå’Œæ”¯æŒæ¥å®ç°ï¼Œæ‰æœ‰äº†ç”³è¯·çš„åšå£«çš„æƒ³æ³•ï¼Œå¹¶éæ˜¯å…ˆç”³è¯·åšå£«ï¼Œå†è¿›è¡Œç§‘ç ”ã€‚åªæœ‰æ­£ç¡®ç†è§£åšå£«é˜¶æ®µå¯¼å¸ˆå’Œå­¦ç”Ÿçš„å…³ç³»ï¼Œæ‰èƒ½åœ¨ç§‘ç ”ä¸Šæœ‰æ‰€è°“çš„â€œå†²åŠ²â€ã€‚å¯¼å¸ˆåº”è¯¥å›´ç»•å­¦ç”Ÿçš„ç ”ç©¶éœ€æ±‚æä¾›å¸®åŠ©ï¼Œè€Œä¸æ˜¯å­¦ç”Ÿè¢«åŠ¨åœ°è·Ÿéšå¯¼å¸ˆã€‚</p> <div style="text-align: center;"> ï¼ˆç§‘ç ”è¿›åº¦ï¼‰ </div> <p>æ— </p> <div style="text-align: center;"> ï¼ˆå®éªŒå®¤åŠ¨æ€ï¼‰ </div> <p><strong>Nathan Zhangâ€™s Meeting - 30 Mins</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ç›®æ ‡ï¼šäº†è§£å¦‚ä½•å‡†å¤‡RAç”³è¯· -&gt; ç”³è¯·RA -&gt; æ‹¿Return Offer

Question List:
1. (Match) I noticed that Professor Kunle has recently published many papers on Dataflow, and I also found some of his earlier talks on the subject. Does this mean that Professor Kunle's current primary research focus is on how to use Dataflow Architecture to improve computing performance, especially for machine learning? Or could you provide an overview of the current focus of Professor's research group?

2. (Connection) While I'm planning to apply for a PhD starting in 2026, I've decided to accelerate my degree process and aim to graduate in May next year so that I can apply for an on-site Research Assistant position. I'm very interested in the possibility of working with Professor Kunle. Given this, how would you suggest I plan my time between now and then? In the longer term, what qualities does Professor Kunle typically look for in his students? If you could provide some specific examples, that would be very helpful!! Additionally, what are the best ways to stay informed about the latest developments in his lab? Would Google Scholar be a good resource for this?
</code></pre></div></div> <div style="text-align: center;"> ï¼ˆOffice Hourï¼‰ </div> <p>CS 251: 2:00-6:30PM</p> <p>CS 250: 3:00-5:00PM</p>]]></content><author><name></name></author><category term="phd-application"/><category term="phd-application"/><summary type="html"><![CDATA[è¾¾åˆ°ç›®æ ‡çš„è·¯å¾„æœ‰å¾ˆå¤šï¼Œä½†ç›´çº¿æœ€çŸ­ã€‚åœ¨è¿™æ¡ç›´çº¿ä¸Šåˆ†å¸ƒç€éœ€è¦è§£å†³çš„é—®é¢˜ - ç¬¦åˆäºŒå…«å®šå¾‹ã€‚æ¯æ¬¡å‘ç»éªŒä¸°å¯Œçš„äººè¯·æ•™ï¼Œéƒ½æ˜¯åœ¨ç›´çº¿ä¸Šè§£å†³ä¸€ä¸ªå°æ ¸å¿ƒé—®é¢˜ã€‚å› æ­¤ï¼ŒOffice Hourå’Œå‘å‰è¾ˆè¯·æ•™çš„æ—¶é—´å æ¯”è¶Šå¤§ï¼Œæˆæ•ˆè¶Šæ˜¾è‘—ã€‚åœ¨åšå£«é˜¶æ®µï¼Œå¯¼å¸ˆä¸å­¦ç”Ÿçš„å…³ç³»ä¸å†æ˜¯ä¼ ç»Ÿæ„ä¹‰ä¸Šâ€œä¼ é“æˆä¸šè§£æƒ‘â€çš„å¸ˆç”Ÿå…³ç³»ï¼Œè€Œæ›´åƒæ˜¯åå‹¤ä¿éšœå’Œå‰çº¿éƒ¨é˜Ÿã€‚å­¦ç”Ÿå¤„åœ¨ç§‘ç ”å·¥ä½œçš„æœ€å‰çº¿ï¼Œè´Ÿè´£å®é™…çš„ç ”ç©¶å’Œæ¢ç´¢ï¼Œè€Œå¯¼å¸ˆçš„è§’è‰²æ›´å€¾å‘äºä¸ºå­¦ç”Ÿæä¾›èµ„æºã€æŒ‡å¯¼æ–¹å‘å’Œä»¥åŠä¸ºå­¦ç”Ÿé—¯çš„ç¥¸å…œåº•ã€‚è¿™æ„å‘³ä¼˜ç§€çš„åšå£«å€™é€‰äººå¸¸å¸¸æ˜¯å…ˆæœ‰äº†å¼ºçƒˆçš„ç§‘ç ”æ„¿æœ›ï¼Œå¹¶ä¸”éœ€è¦èµ„æºå’Œæ”¯æŒæ¥å®ç°ï¼Œæ‰æœ‰äº†ç”³è¯·çš„åšå£«çš„æƒ³æ³•ï¼Œå¹¶éæ˜¯å…ˆç”³è¯·åšå£«ï¼Œå†è¿›è¡Œç§‘ç ”ã€‚åªæœ‰æ­£ç¡®ç†è§£åšå£«é˜¶æ®µå¯¼å¸ˆå’Œå­¦ç”Ÿçš„å…³ç³»ï¼Œæ‰èƒ½åœ¨ç§‘ç ”ä¸Šæœ‰æ‰€è°“çš„â€œå†²åŠ²â€ã€‚å¯¼å¸ˆåº”è¯¥å›´ç»•å­¦ç”Ÿçš„ç ”ç©¶éœ€æ±‚æä¾›å¸®åŠ©ï¼Œè€Œä¸æ˜¯å­¦ç”Ÿè¢«åŠ¨åœ°è·Ÿéšå¯¼å¸ˆã€‚]]></summary></entry><entry><title type="html">åšå£«ç”³è¯·è®°å½•(1)</title><link href="https://aabbccdkg.github.io/blog/2024/phd-application(1)/" rel="alternate" type="text/html" title="åšå£«ç”³è¯·è®°å½•(1)"/><published>2024-09-01T00:32:13+00:00</published><updated>2024-09-01T00:32:13+00:00</updated><id>https://aabbccdkg.github.io/blog/2024/phd-application(1)</id><content type="html" xml:base="https://aabbccdkg.github.io/blog/2024/phd-application(1)/"><![CDATA[<p>ä»Šå¤©æ˜¯2024å¹´9æœˆ1æ—¥ã€‚æˆ‘è®¡åˆ’ç”³è¯·2026å¹´å¼€å§‹çš„åšå£«å­¦ä½ã€‚æŒ‰ç…§å¾€å¹´æƒ…å†µæ¨ç®—ï¼Œç”³è¯·ææ–™ä¼šåœ¨2025å¹´12æœˆå¼€å§‹é™†ç»­è¢«è¦æ±‚æäº¤ï¼Œé¢è¯•å°†åœ¨2026å¹´1æœˆåº•å‰ç»“æŸã€‚å› æ­¤ï¼Œå¤§æ¦‚æœ‰15ä¸ªæœˆçš„æ—¶é—´æ¥å‡†å¤‡ç”³è¯·ã€‚æˆ‘å¸Œæœ›é€šè¿‡è¿™ä¸ªåšå®¢ç³»åˆ—ï¼Œè®°å½•ä¸‹ç”³è¯·è¿‡ç¨‹ã€‚</p> <div style="text-align: center;"> ï¼ˆåºç« ï¼‰ </div> <p>åšå£«ç”³è¯·ä¸­æœ€é‡è¦çš„ä¸¤ä¸ªå› ç´ æ˜¯äººè„‰(Connection)å’Œå¥‘åˆåº¦(Match)ã€‚</p> <p>ç”³è¯·è€…å¾ˆå®¹æ˜“å¤¸å¤§è‡ªå·±çš„ç®€å†ï¼Œå› æ­¤å¯¹åšå£«ç”Ÿå¯¼å¸ˆæ¥è¯´ï¼Œæ¥è‡ªå€¼å¾—ä¿¡ä»»ä¹‹äººçš„æ¨èä¿¡è‡³å…³é‡è¦ï¼Œå®ƒæ„å‘³ç€æ¨èäººç”¨è‡ªå·±çš„å­¦æœ¯å£°èª‰æ‹…ä¿è¯¥ç”³è¯·è€…ç»å†çš„çœŸå®æ€§ã€‚</p> <p>å¤§å¤šæ•°åšå£«ç”Ÿå¯¼å¸ˆéƒ½é¢ä¸´ç€å‘è¡¨è®ºæ–‡çš„å‹åŠ›ï¼Œå› æ­¤ä»–ä»¬é€šå¸¸æ›´å€¾å‘äºé‚£äº›äº†è§£è‡ªå·±ç ”ç©¶æ–¹å‘å¹¶èƒ½å¿«é€Ÿè¿›å…¥å·¥ä½œçŠ¶æ€çš„å€™é€‰äººï¼Œå› ä¸ºå¤§éƒ¨åˆ†ç§‘ç ”å·¥ä½œæ˜¯åŠªåŠ›å¤§äºå¤©èµ‹ã€‚</p> <p>æ‰€ä»¥æˆ‘è®¤ä¸ºï¼Œæ¯”è¾ƒæœ‰æ•ˆçš„ç”³åšæ–¹å¼ï¼Œæ˜¯åœ¨å¿ƒä»ªçš„è¯¾é¢˜ç»„è¿›è¡ŒResearch Internï¼Œæ‹¿Return Offerã€‚ä¸€æ¥æ¨èäººå°±æ˜¯è‡ªå·±çš„åšå£«ç”Ÿå¯¼å¸ˆï¼ŒäºŒæ¥å¯ä»¥ä¿è¯ç§‘ç ”æ–¹å‘100%å’Œå¯¼å¸ˆå¥‘åˆã€‚</p> <p>æˆ‘è¯»Ph.D.çš„åˆå¿ƒå¹¶éå‡ºäºå¯¹ç§‘ç ”çš„çƒ­çˆ±ï¼Œè€Œæ˜¯å¸Œæœ›æ‹¥æœ‰åæ ¡çš„Doctorå¤´è¡”ã€‚å®é™…ä¸Šï¼Œç›®å‰æœ€æ¸´æœ›çš„äº‹æ˜¯åˆ›ä¸šã€‚å› æ­¤ï¼Œå¯¹äºPh.D.çš„ç”³è¯·æ¥è¯´ï¼Œæˆ‘å¸Œæœ›ç”¨æœ€æœ‰æ•ˆçš„æ–¹å¼ - æ ¹æ®å¿ƒä»ªçš„å¯¼å¸ˆï¼Œå®šåˆ¶è‡ªå·±çš„èƒŒæ™¯ã€‚</p> <p>ç›®å‰ï¼Œæˆ‘å¿ƒä»ªçš„å¯¼å¸ˆæ˜¯Stanfordçš„Christoså’ŒKunleï¼Œä»¥åŠMITçš„Danielã€‚æˆ‘çš„è®¡åˆ’æ˜¯åœ¨Prof. Muhammadè¯¾é¢˜ç»„ä¸­å‚ä¸å‘è¡¨ä¸€ç¯‡è®ºæ–‡ï¼Œå¹¶é€šè¿‡ä»–çš„å¸®åŠ©ï¼Œäº‰å–åœ¨ä»Šå¹´å¯’å‡ï¼ˆ12æœˆï¼‰ä¹‹å‰åŠ å…¥Christoså’ŒKunleçš„ç ”ç©¶ç»„ï¼Œæ‹…ä»»Research Internï¼ŒåŒæ—¶å¯†åˆ‡å…³æ³¨Danielå®éªŒå®¤çš„è¿›å±•ã€‚åœ¨æ¥ä¸‹æ¥é•¿è¾¾11ä¸ªæœˆçš„Research Intern(äº‰å–2025å¹´5æœˆæ¯•ä¸šï¼Œè¿™æ ·å°±æœ‰7ä¸ªæœˆçš„çº¿ä¸‹ç§‘ç ”)ä¸­ï¼ŒåŠªåŠ›äº‰å–è·å¾—Return Offerã€‚å› æ­¤ï¼Œæ¥ä¸‹æ¥çš„åšå®¢å°†åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šProf. Muhammadè¯¾é¢˜ç»„çš„ç§‘ç ”è¿›åº¦ï¼›å¿ƒä»ªå¯¼å¸ˆå®éªŒå®¤çš„æœ€æ–°åŠ¨æ€ã€‚</p>]]></content><author><name></name></author><category term="phd-application"/><category term="phd-application"/><summary type="html"><![CDATA[ä»Šå¤©æ˜¯2024å¹´9æœˆ1æ—¥ã€‚æˆ‘è®¡åˆ’ç”³è¯·2026å¹´å¼€å§‹çš„åšå£«å­¦ä½ã€‚æŒ‰ç…§å¾€å¹´æƒ…å†µæ¨ç®—ï¼Œç”³è¯·ææ–™ä¼šåœ¨2025å¹´12æœˆå¼€å§‹é™†ç»­è¢«è¦æ±‚æäº¤ï¼Œé¢è¯•å°†åœ¨2026å¹´1æœˆåº•å‰ç»“æŸã€‚å› æ­¤ï¼Œå¤§æ¦‚æœ‰15ä¸ªæœˆçš„æ—¶é—´æ¥å‡†å¤‡ç”³è¯·ã€‚æˆ‘å¸Œæœ›é€šè¿‡è¿™ä¸ªåšå®¢ç³»åˆ—ï¼Œè®°å½•ä¸‹ç”³è¯·è¿‡ç¨‹ã€‚]]></summary></entry><entry><title type="html">Top Research Labs in Machine Learning Systems (MLSys) ğŸ”¬</title><link href="https://aabbccdkg.github.io/blog/2024/mlsys-labs-intro/" rel="alternate" type="text/html" title="Top Research Labs in Machine Learning Systems (MLSys) ğŸ”¬"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://aabbccdkg.github.io/blog/2024/mlsys-labs-intro</id><content type="html" xml:base="https://aabbccdkg.github.io/blog/2024/mlsys-labs-intro/"><![CDATA[<p>This is a brief introduction to top-tier MLSys labs for Ph.D. applicants, with a primary focus on those in the United States and mainland China. If there are any omissions, please feel free to <a href="mailto:wangdong0502@gmail.com">contact me</a> to add them.</p> <h1 id="-united-states">ğŸ‡ºğŸ‡¸ United States</h1> <h2 id="google-brain"><a href="https://research.google/">Google Brain</a></h2> <h2 id="microsoft-research-msr"><a href="https://www.microsoft.com/en-us/research/">Microsoft Research (MSR)</a></h2> <ul> <li><a href="https://www.microsoft.com/en-us/research/project/fiddle/">Fast and Efficient Infrastructure for Distributed Deep Learning (Fiddle)</a></li> </ul> <h2 id="catalyst-carnegie-mellon-university"><a href="https://catalyst.cs.cmu.edu/">Catalyst (Carnegie Mellon University)</a></h2> <ul> <li> <p><a href="https://www.cs.cmu.edu/~epxing/">Eric Xing: </a> Prof. Eric was a student of <a href="https://people.eecs.berkeley.edu/~jordan/">Prof. Michael I. Jordan</a>.</p> </li> <li> <p><a href="https://tqchen.com/">Tianqi Chen: </a></p> <ul> <li> <p><a href="https://tvm.apache.org/">TVM: </a> TVM is an open-source framework for optimizing and deploying deep learning models, with its name derived from â€œTensor Virtual Machine.â€ Its primary goal is to optimize and compile deep learning models in an automated manner, enabling efficient execution on various hardware platforms such as CPUs, GPUs, FPGAs, and specialized AI accelerators.</p> </li> <li> <p><a href="https://xgboost.readthedocs.io/en/stable/">XGBoost: </a>XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.</p> </li> <li> <p><a href="https://github.com/apache/mxnet">MXNet: </a>Apache MXNet is a deep learning framework designed for both efficiency and flexibility. It allows you to mix symbolic and imperative programming to maximize efficiency and productivity. At its core, MXNet contains a dynamic dependency scheduler that automatically parallelizes both symbolic and imperative operations on the fly. A graph optimization layer on top of that makes symbolic execution fast and memory efficient. MXNet is portable and lightweight, scalable to many GPUs and machines.</p> </li> </ul> </li> <li> <p><a href="https://www.cs.cmu.edu/~zhihaoj2/">Zhihao Jia: </a> Prof. Zhihao Jia is a student of <a href="https://people.eecs.berkeley.edu/~matei/">Prof. Matei Zaharia (now at UC Berkeley)</a>. He seems to be more focused on system for LLM.</p> <ul> <li><a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://cs.stanford.edu/~padon/taso-sosp19.pdf">TASO: </a></li> <li><a href="https://flexflow.ai/">Flexflow: </a></li> </ul> </li> </ul> <h2 id="dsail-mit"><a href="https://dsail.csail.mit.edu/">DSAIL (MIT)</a></h2> <ul> <li> <p><a href="https://hanlab.mit.edu/songhan">Song Han: </a>Pruning and Sparse related work. Prof. Song Han seems to be working on algorithm modifications and hardware, and heâ€™s not really focused on TinyML anymore. Now heâ€™s working on diffusion models and LLM models.</p> </li> <li> <p><a href="https://people.csail.mit.edu/kraska/">Tim Kraska: </a></p> </li> </ul> <h2 id="csail-mit"><a href="https://www.csail.mit.edu/">CSAIL (MIT)</a></h2> <ul> <li> <p><a href="https://people.csail.mit.edu/kraska/">Tim Kraska: </a> Learned Index</p> </li> <li> <p><a href="https://www.csail.mit.edu/person/saman-amarasinghe">Saman Amarasinghe: </a></p> <ul> <li><a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://people.csail.mit.edu/jrk/halide-pldi13.pdf">Halide</a></li> <li><a href="https://tacos.libraries.mit.edu/">TACO</a></li> </ul> </li> </ul> <h2 id="dawn-project-stanford"><a href="https://dawn.cs.stanford.edu/">DAWN Project (Stanford)</a></h2> <ul> <li><a href="https://people.eecs.berkeley.edu/~matei/">Matei Zaharia (now at UC Berkeley): </a> Prof. Matei Zaharia (Stanford &amp; Databricks) is highly respected for building <a href="https://spark.apache.org/">Apache Spark</a> (one of the most widely used frameworks for distributed data processing, and co-started other datacenter software such as Apache Mesos and Spark Streaming) from scratch to a billion-dollar level. He serves as a PC and chair for major conferences. PipeDream, TASO, and FlexFlow is the project built by his Ph.D. student Zhihao Jia. One standout aspect of his research is that it addresses real system needs, making it impactful and practical. Not all his work prioritizes performance; for instance, one recent paper discusses offloading computation to GPUs using annotation for ease of use. Overall, pursuing a PhD under his guidance would likely lead to significant influence in the industry.</li> </ul> <h2 id="hazy-research-stanford-ai-lab"><a href="https://hazyresearch.stanford.edu/index">Hazy Research (Stanford AI Lab)</a></h2> <p>This research group focuses on MLSys and also organized a seminar series called <a href="https://mlsys.stanford.edu/">Stanford MLSys Seminar Series</a>.</p> <h2 id="riselab-university-of-california-berkeley"><a href="https://rise.cs.berkeley.edu/">RISELab (University of California, Berkeley)</a></h2> <ul> <li> <p><a href="https://people.eecs.berkeley.edu/~istoica/">Ion Stoica: </a></p> </li> <li> <p><a href="https://people.eecs.berkeley.edu/~jordan/">Michael Jordan: </a></p> </li> </ul> <p>Most recent project: <a href="https://rise.cs.berkeley.edu/projects/ray/">Ray</a></p> <p>Professors at RISE Lab have offered a course called <a href="https://ucbrise.github.io/cs294-ai-sys-fa19/">AI for Systems and Systems for AI (CS294)</a>.</p> <h2 id="system-lab-university-of-washington"><a href="https://www.cs.washington.edu/research/systems">System Lab (University of Washington)</a></h2> <ul> <li><a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze: </a> Prof. Luis Ceze focuses on Programming Language and Computer Architecture. <ul> <li><a href="https://tvm.apache.org/">TVM: </a> TVM is an open-source framework for optimizing and deploying deep learning models, with its name derived from â€œTensor Virtual Machine.â€ Its primary goal is to optimize and compile deep learning models in an automated manner, enabling efficient execution on various hardware platforms such as CPUs, GPUs, FPGAs, and specialized AI accelerators.</li> </ul> </li> <li><a href="https://www.cs.washington.edu/people/faculty/arvind">Arvind Krishnamurthy: </a> Prof. Arvind Krishnamurthy primarily focuses on computer networks. His work involves applying networking technology to address challenges in distributed machine learning. So there is always cutting-edge support in the field of networking.</li> </ul> <h2 id="sample-university-of-washington"><a href="https://sampl.cs.washington.edu/">Sample (University of Washington)</a></h2> <h2 id="symbioticlab-university-of-michigan-ann-arbor"><a href="https://symbioticlab.org/">SymbioticLab (University of Michigan, Ann Arbor)</a></h2> <ul> <li><a href="https://www.mosharaf.com/">Mosharaf Chowdhury (the academic leader): </a> Prof. Mosharaf is a student of <a href="https://people.eecs.berkeley.edu/~istoica/">Prof. Ion Stoica</a>. He offers the course <a href="https://github.com/mosharaf/eecs598/tree/w21-ai">Systems for AI (EECS598)</a>.</li> </ul> <h2 id="system-group-new-york-university"><a href="http://www.news.cs.nyu.edu/">System Group (New York University)</a></h2> <ul> <li><a href="https://cims.nyu.edu/people/profiles/LI_Jinyang.html">Jinyang Li: </a> She is the Ph.D. advisor of <a href="https://jermainewang.github.io/">Dr. Minjie Wang</a>(the author of DGL).</li> </ul> <h2 id="shivaram-venkataraman-research-group-university-of-wisconsin-madison"><a href="https://shivaram.org/">Shivaram Venkataraman Research Group (University of Wisconsin, Madison)</a></h2> <ul> <li><a href="https://shivaram.org/">Shivaram Venkataraman: </a> Prof. Shivaram is the student of <a href="https://people.eecs.berkeley.edu/~istoica/">Prof. Ion Stoica</a>. He understands more about machine learning and less about systems. The papers he published is not too many, but the workload is substantial.</li> </ul> <h2 id="ecosystem-university-of-toronto"><a href="https://www.cs.toronto.edu/ecosystem/">EcoSystem (University of Toronto)</a></h2> <ul> <li><a href="https://www.cs.toronto.edu/~pekhimenko/">Gennady Pekhimenko: </a></li> </ul> <h1 id="-china">ğŸ‡¨ğŸ‡³ China</h1> <p>In mainland China, it seems that most of the work in MLSys is being done in companies. However, some strong teams in distributed systems often also work on MLSys to some extent, such as <a href="https://ipads.se.sjtu.edu.cn/zh/index.html">IPADS (Shanghai Jiaotong Univeristy)</a>.</p> <h2 id="microsoft-research-labasia"><a href="https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/">Microsoft Research Lab(Asia)</a></h2> <h2 id="pacman-grouptsinghua"><a href="https://pacman.cs.tsinghua.edu.cn/">PACMAN Group(Tsinghua)</a></h2> <p>More related to Arch</p> <h2 id="center-for-energy-efficient-computing-and-applicationspeking-university"><a href="https://ceca.pku.edu.cn/people/index.htm">Center for Energy-efficient Computing and Applications(Peking University)</a></h2> <p>More related to Arch</p> <h2 id="cheng-lis-research-group-univeristy-of-science-and-technology-china"><a href="http://staff.ustc.edu.cn/~chengli7">Cheng LIâ€™s Research Group (Univeristy of Science and Technology China)</a></h2> <h2 id="ipadsshanghai-jiaotong-univeristy"><a href="https://ipads.se.sjtu.edu.cn/zh/index.html">IPADS(Shanghai Jiaotong Univeristy)</a></h2> <p>The best System Lab in Mainland China, and now is also working on some MLSys projects.</p> <h1 id="-appendix">ğŸŒŸ Appendix</h1> <h2 id="some-people-worth-following-on-zhihu">Some people worth following on Zhihu</h2> <ul> <li> <p><a href="https://www.zhihu.com/people/crowowrk">Tianqi Chen: </a> Dr. Tianqi Chen is currently an Assistant Professor at Carnegie Mellon University. He helps run the <a href="https://catalyst.cs.cmu.edu/">Catalyst Group</a>.</p> </li> <li> <p><a href="https://www.zhihu.com/people/zhanghuaizheng">Huaizheng Zhang: </a> Dr. Huaizheng Zhangâ€™s <a href="https://github.com/HuaizhengZhang/AI-System-School">AI-System-School</a> is an open project aimed at collecting and organizing research papers, tools, and resources related to MLSys, Large Language Models (LLM), and Generative AI (GenAI). It provides researchers and engineers with a systematic learning path and practical guide to help them better understand and apply these cutting-edge technologies. Here is his <a href="https://huaizheng.xyz/">personal website</a>.</p> </li> <li> <p><a href="https://www.zhihu.com/people/breaknever">Yue Zhao: </a> Dr. Yue Zhang is currently an Assistant Professor at the University of Southern California. He was also a student of Prof. Zhihao Jia. Here is his <a href="https://github.com/yzhao062">personal website</a>.</p> </li> </ul>]]></content><author><name></name></author><category term="MLSys-Learning-Journal"/><category term="MLSys-Learning-Journal"/><summary type="html"><![CDATA[A brief introduction to top-tier MLSys labs for Ph.D. applicants.]]></summary></entry></feed>