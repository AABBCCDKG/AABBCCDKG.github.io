<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://aabbccdkg.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://aabbccdkg.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-04T22:25:40+00:00</updated><id>https://aabbccdkg.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">博士申请记录(2)</title><link href="https://aabbccdkg.github.io/blog/2024/phd-application(2)/" rel="alternate" type="text/html" title="博士申请记录(2)"/><published>2024-09-04T00:32:13+00:00</published><updated>2024-09-04T00:32:13+00:00</updated><id>https://aabbccdkg.github.io/blog/2024/phd-application(2)</id><content type="html" xml:base="https://aabbccdkg.github.io/blog/2024/phd-application(2)/"><![CDATA[<p>达到目标的路径有很多，但直线最短。在这条直线上分布着需要解决的问题 - 符合二八定律。每次向经验丰富的人请教，都是在直线上解决一个小核心问题。因此，Office Hour和向前辈请教的时间占比越大，成效越显著。在博士阶段，导师与学生的关系不再是传统意义上“传道授业解惑”的师生关系，而更像是后勤保障和前线部队。学生处在科研工作的最前线，负责实际的研究和探索，而导师的角色更倾向于为学生提供资源、指导方向和以及为学生闯的祸兜底。这意味优秀的博士候选人常常是先有了强烈的科研愿望，并且需要资源和支持来实现，才有了申请的博士的想法，并非是先申请博士，再进行科研。只有正确理解博士阶段导师和学生的关系，才能在科研上有所谓的“冲劲”。导师应该围绕学生的研究需求提供帮助，而不是学生被动地跟随导师。</p> <div style="text-align: center;"> （科研进度） </div> <p>无</p> <div style="text-align: center;"> （实验室动态） </div> <p><strong>Nathan Zhang’s Meeting - 30 Mins</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>目标：了解如何准备RA申请 -&gt; 申请RA -&gt; 拿Return Offer

Question List:
1. (Match) I noticed that Professor Kunle has recently published many papers on Dataflow, and I also found some of his earlier talks on the subject. Does this mean that Professor Kunle's current primary research focus is on how to use Dataflow Architecture to improve computing performance, especially for machine learning? Or could you provide an overview of the current focus of Professor's research group?

2. (Connection) While I'm planning to apply for a PhD starting in 2026, I've decided to accelerate my degree process and aim to graduate in May next year so that I can apply for an on-site Research Assistant position. I'm very interested in the possibility of working with Professor Kunle. Given this, how would you suggest I plan my time between now and then? In the longer term, what qualities does Professor Kunle typically look for in his students? If you could provide some specific examples, that would be very helpful!! Additionally, what are the best ways to stay informed about the latest developments in his lab? Would Google Scholar be a good resource for this?
</code></pre></div></div> <div style="text-align: center;"> （Office Hour） </div> <p>CS 251: 2:00-6:30PM</p> <p>CS 250: 3:00-5:00PM</p>]]></content><author><name></name></author><category term="phd-application"/><category term="phd-application"/><summary type="html"><![CDATA[达到目标的路径有很多，但直线最短。在这条直线上分布着需要解决的问题 - 符合二八定律。每次向经验丰富的人请教，都是在直线上解决一个小核心问题。因此，Office Hour和向前辈请教的时间占比越大，成效越显著。在博士阶段，导师与学生的关系不再是传统意义上“传道授业解惑”的师生关系，而更像是后勤保障和前线部队。学生处在科研工作的最前线，负责实际的研究和探索，而导师的角色更倾向于为学生提供资源、指导方向和以及为学生闯的祸兜底。这意味优秀的博士候选人常常是先有了强烈的科研愿望，并且需要资源和支持来实现，才有了申请的博士的想法，并非是先申请博士，再进行科研。只有正确理解博士阶段导师和学生的关系，才能在科研上有所谓的“冲劲”。导师应该围绕学生的研究需求提供帮助，而不是学生被动地跟随导师。]]></summary></entry><entry><title type="html">博士申请记录(1)</title><link href="https://aabbccdkg.github.io/blog/2024/phd-application(1)/" rel="alternate" type="text/html" title="博士申请记录(1)"/><published>2024-09-01T00:32:13+00:00</published><updated>2024-09-01T00:32:13+00:00</updated><id>https://aabbccdkg.github.io/blog/2024/phd-application(1)</id><content type="html" xml:base="https://aabbccdkg.github.io/blog/2024/phd-application(1)/"><![CDATA[<p>今天是2024年9月1日。我计划申请2026年开始的博士学位。按照往年情况推算，申请材料会在2025年12月开始陆续被要求提交，面试将在2026年1月底前结束。因此，大概有15个月的时间来准备申请。我希望通过这个博客系列，记录下申请过程。</p> <div style="text-align: center;"> （序章） </div> <p>博士申请中最重要的两个因素是人脉(Connection)和契合度(Match)。</p> <p>申请者很容易夸大自己的简历，因此对博士生导师来说，来自值得信任之人的推荐信至关重要，它意味着推荐人用自己的学术声誉担保该申请者经历的真实性。</p> <p>大多数博士生导师都面临着发表论文的压力，因此他们通常更倾向于那些了解自己研究方向并能快速进入工作状态的候选人，因为大部分科研工作是努力大于天赋。</p> <p>所以我认为，比较有效的申博方式，是在心仪的课题组进行Research Intern，拿Return Offer。一来推荐人就是自己的博士生导师，二来可以保证科研方向100%和导师契合。</p> <p>我读Ph.D.的初心并非出于对科研的热爱，而是希望拥有名校的Doctor头衔。实际上，目前最渴望的事是创业。因此，对于Ph.D.的申请来说，我希望用最有效的方式 - 根据心仪的导师，定制自己的背景。</p> <p>目前，我心仪的导师是Stanford的Christos和Kunle，以及MIT的Daniel。我的计划是在Prof. Muhammad课题组中参与发表一篇论文，并通过他的帮助，争取在今年寒假（12月）之前加入Christos和Kunle的研究组，担任Research Intern，同时密切关注Daniel实验室的进展。在接下来长达11个月的Research Intern(争取2025年5月毕业，这样就有7个月的线下科研)中，努力争取获得Return Offer。因此，接下来的博客将分为两部分：Prof. Muhammad课题组的科研进度；心仪导师实验室的最新动态。</p>]]></content><author><name></name></author><category term="phd-application"/><category term="phd-application"/><summary type="html"><![CDATA[今天是2024年9月1日。我计划申请2026年开始的博士学位。按照往年情况推算，申请材料会在2025年12月开始陆续被要求提交，面试将在2026年1月底前结束。因此，大概有15个月的时间来准备申请。我希望通过这个博客系列，记录下申请过程。]]></summary></entry><entry><title type="html">Top Research Labs in Machine Learning Systems (MLSys) 🔬</title><link href="https://aabbccdkg.github.io/blog/2024/mlsys-labs-intro/" rel="alternate" type="text/html" title="Top Research Labs in Machine Learning Systems (MLSys) 🔬"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://aabbccdkg.github.io/blog/2024/mlsys-labs-intro</id><content type="html" xml:base="https://aabbccdkg.github.io/blog/2024/mlsys-labs-intro/"><![CDATA[<p>This is a brief introduction to top-tier MLSys labs for Ph.D. applicants, with a primary focus on those in the United States and mainland China. If there are any omissions, please feel free to <a href="mailto:wangdong0502@gmail.com">contact me</a> to add them.</p> <h1 id="-united-states">🇺🇸 United States</h1> <h2 id="google-brain"><a href="https://research.google/">Google Brain</a></h2> <h2 id="microsoft-research-msr"><a href="https://www.microsoft.com/en-us/research/">Microsoft Research (MSR)</a></h2> <ul> <li><a href="https://www.microsoft.com/en-us/research/project/fiddle/">Fast and Efficient Infrastructure for Distributed Deep Learning (Fiddle)</a></li> </ul> <h2 id="catalyst-carnegie-mellon-university"><a href="https://catalyst.cs.cmu.edu/">Catalyst (Carnegie Mellon University)</a></h2> <ul> <li> <p><a href="https://www.cs.cmu.edu/~epxing/">Eric Xing: </a> Prof. Eric was a student of <a href="https://people.eecs.berkeley.edu/~jordan/">Prof. Michael I. Jordan</a>.</p> </li> <li> <p><a href="https://tqchen.com/">Tianqi Chen: </a></p> <ul> <li> <p><a href="https://tvm.apache.org/">TVM: </a> TVM is an open-source framework for optimizing and deploying deep learning models, with its name derived from “Tensor Virtual Machine.” Its primary goal is to optimize and compile deep learning models in an automated manner, enabling efficient execution on various hardware platforms such as CPUs, GPUs, FPGAs, and specialized AI accelerators.</p> </li> <li> <p><a href="https://xgboost.readthedocs.io/en/stable/">XGBoost: </a>XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.</p> </li> <li> <p><a href="https://github.com/apache/mxnet">MXNet: </a>Apache MXNet is a deep learning framework designed for both efficiency and flexibility. It allows you to mix symbolic and imperative programming to maximize efficiency and productivity. At its core, MXNet contains a dynamic dependency scheduler that automatically parallelizes both symbolic and imperative operations on the fly. A graph optimization layer on top of that makes symbolic execution fast and memory efficient. MXNet is portable and lightweight, scalable to many GPUs and machines.</p> </li> </ul> </li> <li> <p><a href="https://www.cs.cmu.edu/~zhihaoj2/">Zhihao Jia: </a> Prof. Zhihao Jia is a student of <a href="https://people.eecs.berkeley.edu/~matei/">Prof. Matei Zaharia (now at UC Berkeley)</a>. He seems to be more focused on system for LLM.</p> <ul> <li><a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://cs.stanford.edu/~padon/taso-sosp19.pdf">TASO: </a></li> <li><a href="https://flexflow.ai/">Flexflow: </a></li> </ul> </li> </ul> <h2 id="dsail-mit"><a href="https://dsail.csail.mit.edu/">DSAIL (MIT)</a></h2> <ul> <li> <p><a href="https://hanlab.mit.edu/songhan">Song Han: </a>Pruning and Sparse related work. Prof. Song Han seems to be working on algorithm modifications and hardware, and he’s not really focused on TinyML anymore. Now he’s working on diffusion models and LLM models.</p> </li> <li> <p><a href="https://people.csail.mit.edu/kraska/">Tim Kraska: </a></p> </li> </ul> <h2 id="csail-mit"><a href="https://www.csail.mit.edu/">CSAIL (MIT)</a></h2> <ul> <li> <p><a href="https://people.csail.mit.edu/kraska/">Tim Kraska: </a> Learned Index</p> </li> <li> <p><a href="https://www.csail.mit.edu/person/saman-amarasinghe">Saman Amarasinghe: </a></p> <ul> <li><a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://people.csail.mit.edu/jrk/halide-pldi13.pdf">Halide</a></li> <li><a href="https://tacos.libraries.mit.edu/">TACO</a></li> </ul> </li> </ul> <h2 id="dawn-project-stanford"><a href="https://dawn.cs.stanford.edu/">DAWN Project (Stanford)</a></h2> <ul> <li><a href="https://people.eecs.berkeley.edu/~matei/">Matei Zaharia (now at UC Berkeley): </a> Prof. Matei Zaharia (Stanford &amp; Databricks) is highly respected for building <a href="https://spark.apache.org/">Apache Spark</a> (one of the most widely used frameworks for distributed data processing, and co-started other datacenter software such as Apache Mesos and Spark Streaming) from scratch to a billion-dollar level. He serves as a PC and chair for major conferences. PipeDream, TASO, and FlexFlow is the project built by his Ph.D. student Zhihao Jia. One standout aspect of his research is that it addresses real system needs, making it impactful and practical. Not all his work prioritizes performance; for instance, one recent paper discusses offloading computation to GPUs using annotation for ease of use. Overall, pursuing a PhD under his guidance would likely lead to significant influence in the industry.</li> </ul> <h2 id="hazy-research-stanford-ai-lab"><a href="https://hazyresearch.stanford.edu/index">Hazy Research (Stanford AI Lab)</a></h2> <p>This research group focuses on MLSys and also organized a seminar series called <a href="https://mlsys.stanford.edu/">Stanford MLSys Seminar Series</a>.</p> <h2 id="riselab-university-of-california-berkeley"><a href="https://rise.cs.berkeley.edu/">RISELab (University of California, Berkeley)</a></h2> <ul> <li> <p><a href="https://people.eecs.berkeley.edu/~istoica/">Ion Stoica: </a></p> </li> <li> <p><a href="https://people.eecs.berkeley.edu/~jordan/">Michael Jordan: </a></p> </li> </ul> <p>Most recent project: <a href="https://rise.cs.berkeley.edu/projects/ray/">Ray</a></p> <p>Professors at RISE Lab have offered a course called <a href="https://ucbrise.github.io/cs294-ai-sys-fa19/">AI for Systems and Systems for AI (CS294)</a>.</p> <h2 id="system-lab-university-of-washington"><a href="https://www.cs.washington.edu/research/systems">System Lab (University of Washington)</a></h2> <ul> <li><a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze: </a> Prof. Luis Ceze focuses on Programming Language and Computer Architecture. <ul> <li><a href="https://tvm.apache.org/">TVM: </a> TVM is an open-source framework for optimizing and deploying deep learning models, with its name derived from “Tensor Virtual Machine.” Its primary goal is to optimize and compile deep learning models in an automated manner, enabling efficient execution on various hardware platforms such as CPUs, GPUs, FPGAs, and specialized AI accelerators.</li> </ul> </li> <li><a href="https://www.cs.washington.edu/people/faculty/arvind">Arvind Krishnamurthy: </a> Prof. Arvind Krishnamurthy primarily focuses on computer networks. His work involves applying networking technology to address challenges in distributed machine learning. So there is always cutting-edge support in the field of networking.</li> </ul> <h2 id="sample-university-of-washington"><a href="https://sampl.cs.washington.edu/">Sample (University of Washington)</a></h2> <h2 id="symbioticlab-university-of-michigan-ann-arbor"><a href="https://symbioticlab.org/">SymbioticLab (University of Michigan, Ann Arbor)</a></h2> <ul> <li><a href="https://www.mosharaf.com/">Mosharaf Chowdhury (the academic leader): </a> Prof. Mosharaf is a student of <a href="https://people.eecs.berkeley.edu/~istoica/">Prof. Ion Stoica</a>. He offers the course <a href="https://github.com/mosharaf/eecs598/tree/w21-ai">Systems for AI (EECS598)</a>.</li> </ul> <h2 id="system-group-new-york-university"><a href="http://www.news.cs.nyu.edu/">System Group (New York University)</a></h2> <ul> <li><a href="https://cims.nyu.edu/people/profiles/LI_Jinyang.html">Jinyang Li: </a> She is the Ph.D. advisor of <a href="https://jermainewang.github.io/">Dr. Minjie Wang</a>(the author of DGL).</li> </ul> <h2 id="shivaram-venkataraman-research-group-university-of-wisconsin-madison"><a href="https://shivaram.org/">Shivaram Venkataraman Research Group (University of Wisconsin, Madison)</a></h2> <ul> <li><a href="https://shivaram.org/">Shivaram Venkataraman: </a> Prof. Shivaram is the student of <a href="https://people.eecs.berkeley.edu/~istoica/">Prof. Ion Stoica</a>. He understands more about machine learning and less about systems. The papers he published is not too many, but the workload is substantial.</li> </ul> <h2 id="ecosystem-university-of-toronto"><a href="https://www.cs.toronto.edu/ecosystem/">EcoSystem (University of Toronto)</a></h2> <ul> <li><a href="https://www.cs.toronto.edu/~pekhimenko/">Gennady Pekhimenko: </a></li> </ul> <h1 id="-china">🇨🇳 China</h1> <p>In mainland China, it seems that most of the work in MLSys is being done in companies. However, some strong teams in distributed systems often also work on MLSys to some extent, such as <a href="https://ipads.se.sjtu.edu.cn/zh/index.html">IPADS (Shanghai Jiaotong Univeristy)</a>.</p> <h2 id="microsoft-research-labasia"><a href="https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/">Microsoft Research Lab(Asia)</a></h2> <h2 id="pacman-grouptsinghua"><a href="https://pacman.cs.tsinghua.edu.cn/">PACMAN Group(Tsinghua)</a></h2> <p>More related to Arch</p> <h2 id="center-for-energy-efficient-computing-and-applicationspeking-university"><a href="https://ceca.pku.edu.cn/people/index.htm">Center for Energy-efficient Computing and Applications(Peking University)</a></h2> <p>More related to Arch</p> <h2 id="cheng-lis-research-group-univeristy-of-science-and-technology-china"><a href="http://staff.ustc.edu.cn/~chengli7">Cheng LI’s Research Group (Univeristy of Science and Technology China)</a></h2> <h2 id="ipadsshanghai-jiaotong-univeristy"><a href="https://ipads.se.sjtu.edu.cn/zh/index.html">IPADS(Shanghai Jiaotong Univeristy)</a></h2> <p>The best System Lab in Mainland China, and now is also working on some MLSys projects.</p> <h1 id="-appendix">🌟 Appendix</h1> <h2 id="some-people-worth-following-on-zhihu">Some people worth following on Zhihu</h2> <ul> <li> <p><a href="https://www.zhihu.com/people/crowowrk">Tianqi Chen: </a> Dr. Tianqi Chen is currently an Assistant Professor at Carnegie Mellon University. He helps run the <a href="https://catalyst.cs.cmu.edu/">Catalyst Group</a>.</p> </li> <li> <p><a href="https://www.zhihu.com/people/zhanghuaizheng">Huaizheng Zhang: </a> Dr. Huaizheng Zhang’s <a href="https://github.com/HuaizhengZhang/AI-System-School">AI-System-School</a> is an open project aimed at collecting and organizing research papers, tools, and resources related to MLSys, Large Language Models (LLM), and Generative AI (GenAI). It provides researchers and engineers with a systematic learning path and practical guide to help them better understand and apply these cutting-edge technologies. Here is his <a href="https://huaizheng.xyz/">personal website</a>.</p> </li> <li> <p><a href="https://www.zhihu.com/people/breaknever">Yue Zhao: </a> Dr. Yue Zhang is currently an Assistant Professor at the University of Southern California. He was also a student of Prof. Zhihao Jia. Here is his <a href="https://github.com/yzhao062">personal website</a>.</p> </li> </ul>]]></content><author><name></name></author><category term="MLSys-Learning-Journal"/><category term="MLSys-Learning-Journal"/><summary type="html"><![CDATA[A brief introduction to top-tier MLSys labs for Ph.D. applicants.]]></summary></entry></feed>