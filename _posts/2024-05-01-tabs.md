---
layout: post
title: Top Research Labs in Machine Learning Systems (MLSys)
date: 2024-05-01 00:32:13
description: A brief introduction to top-tier MLSys labs for PhD applications.
tags: formatting code
categories: sample-posts
tabs: true
---

## [Google Brain](https://research.google/)

## Microsoft Research (MSR)
Focus Areas: Distributed systems, deep learning optimization, hardware-software co-design
Highlights: Google Brain and MSR are giants in both academia and industry, contributing significantly to advancements in machine learning infrastructure. Their work spans optimizing deep learning models, developing new frameworks like TensorFlow and PyTorch, and exploring the intersection of ML and systems.

## [Catalyst (Carnegie Mellon University)](https://catalyst.cs.cmu.edu/)
Key Researchers: [Eric Xing](https://www.cs.cmu.edu/~epxing/), [Tianqi Chen](https://tqchen.com/), [Zhihao Jia](https://www.cs.cmu.edu/~zhihaoj2/)
Focus Areas:
Tianqi Chen: TVM, XGBoost, MXNet
Zhihao Jia: TASO

High-performance machine learning, systems for large-scale ML
Highlights: Catalyst Group at CMU is known for pioneering projects like TVM, XGBoost, and TASO, focusing on optimizing machine learning pipelines for performance and scalability. Their work has significant implications for both academic research and industrial applications.

## [DSAIL (MIT)](https://dsail.csail.mit.edu/)
Key Researchers: [Song Han](https://hanlab.mit.edu/songhan), [Tim Kraska](https://people.csail.mit.edu/kraska/)
Song Han: Pruning and Sparse related work


## CSAIL (MIT) 
Key Researchers: Tim Kraska, [Saman Amarasinghe](https://www.csail.mit.edu/person/saman-amarasinghe)
Tim Kraska: Learned Index and a series of after things
Saman Amarasinghe: [Halide](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://people.csail.mit.edu/jrk/halide-pldi13.pdf), [TACO](https://tacos.libraries.mit.edu/)
Focus Areas: Data systems, learned index structures, sparse computing
Highlights: MIT CSAILâ€™s contributions to MLSys include learned index structures that optimize database queries and innovative methods for sparse computing. Their research is fundamental in pushing the boundaries of what is possible in machine learning systems.


## [Stanford DAWN Project](https://dawn.cs.stanford.edu/)
Key Researchers: [Matei Zaharia(now in Cal)](https://people.eecs.berkeley.edu/~matei/),
Matei Zaharia (Stanford & Databricks) is highly respected for building [Apache Spark](https://spark.apache.org/) (one of the most widely used frameworks for distributed data processing, and co-started other datacenter software such as Apache Mesos and Spark Streaming) from scratch to a billion-dollar level. He serves as a PC and chair for major conferences. PipeDream, TASO, and FlexFlow is the project built by his Ph.D. student.Zhihao jia is his Ph.D. student. and  his students' projects like PipeDream, TASO by Zhihao Jia, and FlexFlow. One standout aspect of his research is that it addresses real system needs, making it impactful and practical. Not all his work prioritizes performance; for instance, one recent paper discusses offloading computation to GPUs using annotation for ease of use. Overall, pursuing a PhD under his guidance would likely lead to significant influence in the industry.


## [Hazy Research (Stanford AI Lab)](https://hazyresearch.stanford.edu/index)
This research group will focus on MLSys and also organized a seminar series called [Stanford MLSys Seminar Series](https://mlsys.stanford.edu/)

## [RISELab (University of California, Berkeley)](https://rise.cs.berkeley.edu/)
Key Researchers: Ion Stoica, Michael Jordan
Most recent project: [Ray](https://rise.cs.berkeley.edu/projects/ray/)

Professors at RISE Lab have offered a course called [AI for Systems and Systems for AI (CS294)](https://ucbrise.github.io/cs294-ai-sys-fa19/)


Focus Areas: Distributed computing, AI for systems, systems for AI
Highlights: RISELab is famous for its groundbreaking work on Ray, an open-source project for building distributed applications, and for Spark, which revolutionized big data processing. The lab continues to explore how AI can be leveraged to improve system performance and reliability.

## [System Lab (University of Washington)](https://www.cs.washington.edu/research/systems)
Key Researchers: Luis Ceze, Arvind Krishnamurthy
Focus Areas: AI for systems, systems for AI, serverless computing
Highlights: The UW System Lab focuses on the intersection of AI and systems, with notable contributions in serverless computing and network optimizations for distributed machine learning. Their work has practical implications for cloud computing and AI infrastructure.

## [Sample (University of Washington)](https://sampl.cs.washington.edu/)

## [SymbioticLab (University of Michigan, Ann Arbor)](https://symbioticlab.org/)
Key Researchers: [Mosharaf Chowdhury](https://www.mosharaf.com/)

Professor Mosharaf Chowdhury(the academic leader) is offering the course [Systems for AI (EECS598)](https://github.com/mosharaf/eecs598/tree/w21-ai)

Focus Areas: Distributed systems, networking for AI, big data systems
Highlights: SymbioticLab is dedicated to exploring how distributed systems can be optimized to support large-scale AI workloads. Their research spans from efficient data communication protocols to innovative scheduling algorithms, enhancing the performance of big data and machine learning systems.

## [NYU System Group](http://www.news.cs.nyu.edu/)
Key Researcher: [Jinyang Li](https://cims.nyu.edu/people/profiles/LI_Jinyang.html)
Jinyang Li: The Ph.D. advisor of [Minjie Wang](https://jermainewang.github.io/)(the author of DGL)

## [Shivaram Venkataraman Research Group(University of Wisconsin, Madison)](https://shivaram.org/)


## [EcoSystem at University of Toronto](https://www.cs.toronto.edu/ecosystem/)
Key Researchers: [Gennady Pekhimenko](https://www.cs.toronto.edu/~pekhimenko/)
Focus Areas: Machine learning system optimization, hardware acceleration for ML
Highlights: The EcoSystem lab at UToronto focuses on optimizing machine learning systems through hardware acceleration and efficient software design. Their research helps bridge the gap between cutting-edge ML algorithms and practical, deployable systems.


China:
## [Microsoft Research Lab(Asia)](https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/)

## [PACMAN Group(Tsinghua)](https://pacman.cs.tsinghua.edu.cn/)
more related to Arch

## [Center for Energy-efficient Computing and Applications(Peking University)](https://ceca.pku.edu.cn/people/index.htm)
More related to Arch

## [IPADS(Shanghai Jiaotong Univeristy)](https://ipads.se.sjtu.edu.cn/zh/index.html)
The best System Lab in Mainland China, and now is also working on some MLSys projects


This is how a post with [tabs](https://github.com/Ovski4/jekyll-tabs) looks like. Note that the tabs could be used for different purposes, not only for code.

## First tabs

To add tabs, use the following syntax:

{% raw %}

```liquid
{% tabs group-name %}

{% tab group-name tab-name-1 %}

Content 1

{% endtab %}

{% tab group-name tab-name-2 %}

Content 2

{% endtab %}

{% endtabs %}
```

{% endraw %}

With this you can generate visualizations like:

{% tabs log %}

{% tab log php %}

```php
var_dump('hello');
```

{% endtab %}

{% tab log js %}

```javascript
console.log("hello");
```

{% endtab %}

{% tab log ruby %}

```javascript
pputs 'hello'
```

{% endtab %}

{% endtabs %}

## Another example

{% tabs data-struct %}

{% tab data-struct yaml %}

```yaml
hello:
  - "whatsup"
  - "hi"
```

{% endtab %}

{% tab data-struct json %}

```json
{
  "hello": ["whatsup", "hi"]
}
```

{% endtab %}

{% endtabs %}

## Tabs for something else

{% tabs something-else %}

{% tab something-else text %}

Regular text

{% endtab %}

{% tab something-else quote %}

> A quote

{% endtab %}

{% tab something-else list %}

Hipster list

- brunch
- fixie
- raybans
- messenger bag

{% endtab %}

{% endtabs %}
